{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b12c3be",
   "metadata": {},
   "source": [
    "# Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81d050d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tsfel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#new \u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtsfel\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VarianceThreshold\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tsfel'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "#new \n",
    "import tsfel\n",
    "import sklearn\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc5de7e",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50b86ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(os.path.join('data', 'preprocessed', 'preprocessed_dataset_1.npz'), allow_pickle = True)\n",
    "\n",
    "#training dataset \n",
    "x_train = data['x_train']\n",
    "y_train = data['y_train']\n",
    "idx_train = data['idx_train']\n",
    "\n",
    "#test dataset \n",
    "x_test = data['x_test']\n",
    "idx_test = data['idx_test']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b798bb",
   "metadata": {},
   "source": [
    "# Do feature extraction magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5e4546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD\n",
    "def getFeatures(single_feature_matrix, cfg_file):\n",
    "    new_single_feat_matrix = pd.DataFrame()\n",
    "    for row in single_feature_matrix:\n",
    "        X_sig = pd.DataFrame(np.hstack(row.T), columns=[\"\"])\n",
    "        X_sig = X_sig.dropna() # since na are removed, this should be omitted and also the loop is unnecessary \n",
    "        X = tsfel.time_series_features_extractor(cfg_file, X_sig, window_size=X_sig.shape[0], verbose=\n",
    "        False)\n",
    "\n",
    "        new_single_feat_matrix = pd.concat([new_single_feat_matrix, X])\n",
    "    return new_single_feat_matrix\n",
    "\n",
    "def wrapperFeatures(train_dataset, test_dataset,feature_type):\n",
    "    test_new_feat_dataset = pd.DataFrame()\n",
    "    new_feat_dataset = pd.DataFrame()\n",
    "    # check the domain type of features to extract\n",
    "    if feature_type != '':\n",
    "        cfg_file = tsfel.get_features_by_domain(feature_type)\n",
    "    else:\n",
    "        cfg_file = tsfel.get_features_by_domain()\n",
    "    \n",
    "    for feat_idx in range(train_dataset.shape[2]):\n",
    "        # for each feature (third dim)\n",
    "        feat_matrix_train = train_dataset[:,:,feat_idx]\n",
    "        feat_matrix_test = test_dataset[:,:,feat_idx]\n",
    "\n",
    "        new_single_feat_matrix = getFeatures(feat_matrix_train, cfg_file)\n",
    "\n",
    "        # Highly correlated features are removed\n",
    "        corr_features = tsfel.correlated_features(new_single_feat_matrix)\n",
    "        new_single_feat_matrix.drop(corr_features, axis=1, inplace=True)\n",
    "        colnames = new_single_feat_matrix.columns\n",
    "        #print(colnames)\n",
    "\n",
    "        # Remove low variance features\n",
    "        ## TODO: (Michele) check this thresholds \n",
    "        selector = VarianceThreshold()\n",
    "        new_single_feat_matrix = selector.fit_transform(new_single_feat_matrix)\n",
    "\n",
    "        # from colnames, keep the ones that are labeled as true (e.g. variance sufficently high) and transform from ndarray to dataframe\n",
    "        new_single_feat_matrix = pd.DataFrame(data= new_single_feat_matrix, columns = [colnames[i] for i in range(len(colnames)) if selector.get_support()[i]])\n",
    "        new_colnames = new_single_feat_matrix.columns #colnames store in order to keep only these one also in the test set\n",
    "        \n",
    "        #rename such that same features names have different \"label\" related to handcrafted features index\n",
    "        index_related_column_names = [\"handcrafted{}_{}\".format(feat_idx,new_single_feat_matrix.columns[idx]) for idx in range(len(new_single_feat_matrix.columns))]\n",
    "        new_single_feat_matrix.columns = index_related_column_names\n",
    "\n",
    "        new_feat_dataset = pd.concat([new_feat_dataset, new_single_feat_matrix], axis=1)\n",
    "\n",
    "        ### test section ###\n",
    "        test_new_single_feat_matrix = getFeatures(feat_matrix_test, cfg_file)\n",
    "\n",
    "        test_new_single_feat_matrix = pd.DataFrame(data= test_new_single_feat_matrix)\n",
    "        # keep the same features extrcated in training \n",
    "        test_new_single_feat_matrix = test_new_single_feat_matrix.drop(columns=[col for col in test_new_single_feat_matrix if col not in new_colnames])\n",
    "        #rename such that same features names have different \"label\" related to handcrafted features index\n",
    "        index_related_column_names = [\"handcrafted{}_{}\".format(feat_idx,test_new_single_feat_matrix.columns[idx]) for idx in range(len(test_new_single_feat_matrix.columns))]\n",
    "        test_new_single_feat_matrix.columns = index_related_column_names\n",
    "\n",
    "        test_new_feat_dataset = pd.concat([test_new_feat_dataset, test_new_single_feat_matrix], axis=1)\n",
    "\n",
    "    return new_feat_dataset, test_new_feat_dataset\n",
    "\n",
    "\n",
    "\n",
    "#train_dataset = handcrafted_features[\"ECG_features\"]\n",
    "#test_dataset = dataset_test[\"hand_crafted_features\"][\"ECG_features\"]\n",
    "feature_type =\"statistical\"\n",
    "\n",
    "newTrain, newTest = wrapperFeatures(x_train, x_test, feature_type)\n",
    "\n",
    "# note: if ecg and gsr are computed, please add a prefix \"ecg or gsr\" before computing the features for each type of signal. \n",
    "\n",
    "# TODO: (Michele) check of each variable data distribution etc..\n",
    "# TODO: better code "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a20fc4",
   "metadata": {},
   "source": [
    "# Save feature extracted dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646b4595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save\n",
    "np.savez(os.path.join('data', 'feature_extracted', 'feature_extracted_dataset_1'), \n",
    "         x_train =newTrain,\n",
    "         y_train = y_train,\n",
    "         idx_train = idx_train,\n",
    "         x_test = newTest,\n",
    "         idx_test = idx_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
