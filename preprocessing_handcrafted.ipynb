{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e7e0cd",
   "metadata": {},
   "source": [
    "# Preprocess data\n",
    "\n",
    "This notebook will create 5 preprocessed datasets (with only handcrafted features):\n",
    "\n",
    "1. ecg+gsr where ecg does not contain nans and it is not all 0\n",
    "2. ecg+gsr where gsr is not all 0\n",
    "3. ecg+gsr where ecg does not contain nans and it is not all 0, and gsr is not all 0\n",
    "4. ecg where ecg does not contain nans and it is not all 0\n",
    "5. gsr where gsr is not all 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b12c3be",
   "metadata": {},
   "source": [
    "# Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81d050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc5de7e",
   "metadata": {},
   "source": [
    "# Load original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50b86ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(os.path.join('data','original', 'dataset_smile_challenge.npy'), allow_pickle = True).item()\n",
    "\n",
    "#training dataset \n",
    "train = data['train']\n",
    "deep_features_train = train['deep_features'] # for deep features {'ECG_features_C', 'ECG_features_T'}.\n",
    "handcrafted_features_train = train['hand_crafted_features'] # for hand-crafted features {'ECG_features', 'GSR_features'}.\n",
    "\n",
    "#test dataset\n",
    "test = data['test']\n",
    "deep_features_test = test['deep_features'] # for deep features {'ECG_features_C', 'ECG_features_T'}.\n",
    "handcrafted_features_test = test['hand_crafted_features'] # for hand-crafted features {'ECG_features', 'GSR_features'}.\n",
    "\n",
    "# extracting labels and converting labels >= 1 to just 1.\n",
    "y_train_orig = train['labels']\n",
    "th = 1\n",
    "y_train_orig[y_train_orig<th] = 0\n",
    "y_train_orig[y_train_orig>0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9c6f1a",
   "metadata": {},
   "source": [
    "# Get original shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59eaddeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of deep_features[ECG_features_C]: (2070, 60, 256)\n",
      "Shape of deep_features[ECG_features_T]: (2070, 60, 64)\n",
      "Shape of handcrafted_features[ECG_features]: (2070, 60, 8)\n",
      "Shape of handcrafted_features[GSR_features]: (2070, 60, 12)\n"
     ]
    }
   ],
   "source": [
    "#Evaluate shapes\n",
    "print('Shape of deep_features[ECG_features_C]: ' + str(deep_features_train['ECG_features_C'].shape))\n",
    "print('Shape of deep_features[ECG_features_T]: ' + str(deep_features_train['ECG_features_T'].shape))\n",
    "\n",
    "print('Shape of handcrafted_features[ECG_features]: ' + str(handcrafted_features_train['ECG_features'].shape))\n",
    "print('Shape of handcrafted_features[GSR_features]: ' + str(handcrafted_features_train['GSR_features'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878ad717",
   "metadata": {},
   "source": [
    "# Dataset 1 creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f82e3c8",
   "metadata": {},
   "source": [
    "# 1a: ECG, find rows with nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11ec90f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ECG rows with nans, TRAIN: 29 out of 2070(1.4009661835748792%)\n",
      "Number of ECG rows with nans, TEST: 73 out of 986(7.403651115618661%)\n"
     ]
    }
   ],
   "source": [
    "#Idxs of nans\n",
    "idx_not_train = np.unique(np.argwhere(np.isnan(handcrafted_features_train['ECG_features']))[:,0]).tolist()\n",
    "\n",
    "#Number of rows with nans\n",
    "print('Number of ECG rows with nans, TRAIN: ' + str(len(idx_not_train)) + ' out of ' + str(handcrafted_features_train['ECG_features'].shape[0]) + '(' + str(100*len(idx_not_train)/handcrafted_features_train['ECG_features'].shape[0]) + '%)')\n",
    "\n",
    "#Idxs of nans\n",
    "idx_not_test = np.unique(np.argwhere(np.isnan(handcrafted_features_test['ECG_features']))[:,0]).tolist()\n",
    "\n",
    "#Number of rows with nans\n",
    "print('Number of ECG rows with nans, TEST: ' + str(len(idx_not_test)) + ' out of ' + str(handcrafted_features_test['ECG_features'].shape[0]) + '(' + str(100*len(idx_not_test)/handcrafted_features_test['ECG_features'].shape[0]) + '%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9278e025",
   "metadata": {},
   "source": [
    "# 1b: ECG, find rows with all 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4f602e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all-0 or nan ECG rows, TRAIN: 256 out of 2070(12.367149758454106%)\n",
      "Number of all-0 or nan ECG rows, TEST: 114 out of 986(11.561866125760648%)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for hft in handcrafted_features_train['ECG_features']:\n",
    "    if np.nansum(hft) == 0:\n",
    "        idx_not_train.append(i)\n",
    "    i = i+1\n",
    "idx_not_train = np.unique(idx_not_train).tolist()\n",
    "print('Number of all-0 or nan ECG rows, TRAIN: ' + str(len(idx_not_train)) +' out of ' + str(handcrafted_features_train['ECG_features'].shape[0]) + '(' + str(100*len(idx_not_train)/handcrafted_features_train['ECG_features'].shape[0]) + '%)')\n",
    "\n",
    "i = 0\n",
    "for hft in handcrafted_features_test['ECG_features']:\n",
    "    if np.nansum(hft) == 0:\n",
    "        idx_not_test.append(i)\n",
    "    i = i+1\n",
    "idx_not_test = np.unique(idx_not_test).tolist()\n",
    "print('Number of all-0 or nan ECG rows, TEST: ' + str(len(idx_not_test)) +' out of ' + str(handcrafted_features_test['ECG_features'].shape[0]) + '(' + str(100*len(idx_not_test)/handcrafted_features_test['ECG_features'].shape[0]) + '%)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfd4ea1",
   "metadata": {},
   "source": [
    "# 1c: Drop and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14d0bd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of rows, TRAIN: 1814 out of 2070 (87.6328502415459%)\n",
      "Final number of rows, TEST: 872 out of 986 (88.43813387423936%)\n",
      "Prevalence of CLASS = 0, TRAIN: 54.07938257993385%\n",
      "Prevalence of CLASS = 1, TRAIN: 45.92061742006615%\n",
      "Saved dataset 1\n"
     ]
    }
   ],
   "source": [
    "#Drop train data\n",
    "x_train = dict()\n",
    "x_train['ECG_features'] = np.delete(handcrafted_features_train['ECG_features'],idx_not_train,axis=0)\n",
    "x_train['GSR_features'] = np.delete(handcrafted_features_train['GSR_features'],idx_not_train,axis=0)\n",
    "y_train = np.delete(y_train_orig,idx_not_train,axis=0)\n",
    "idx_train = [c for c in range(handcrafted_features_train['GSR_features'].shape[0]) if c not in idx_not_train]\n",
    "\n",
    "#Drop test data\n",
    "x_test = dict()\n",
    "x_test['ECG_features'] = np.delete(handcrafted_features_test['ECG_features'],idx_not_test,axis=0)\n",
    "x_test['GSR_features'] = np.delete(handcrafted_features_test['GSR_features'],idx_not_test,axis=0)\n",
    "idx_test = [c for c in range(handcrafted_features_test['GSR_features'].shape[0]) if c not in idx_not_test]\n",
    "\n",
    "#Print stats\n",
    "print('Final number of rows, TRAIN: ' + str(len(idx_train)) +' out of ' + str(handcrafted_features_train['ECG_features'].shape[0]) + ' (' + str(100*len(idx_train)/handcrafted_features_train['ECG_features'].shape[0]) + '%)')\n",
    "print('Final number of rows, TEST: ' + str(len(idx_test)) +' out of ' + str(handcrafted_features_test['ECG_features'].shape[0]) + ' (' + str(100*len(idx_test)/handcrafted_features_test['ECG_features'].shape[0]) + '%)')\n",
    "\n",
    "print('Prevalence of CLASS = 0, TRAIN: ' + str(100*np.sum(y_train)/y_train.shape[0]) + '%')\n",
    "print('Prevalence of CLASS = 1, TRAIN: ' + str(100*(y_train.shape[0]-np.sum(y_train))/y_train.shape[0]) + '%')\n",
    "\n",
    "#Save\n",
    "np.savez(os.path.join('data', 'preprocessed', 'preprocessed_dataset_1'), \n",
    "         x_train =x_train,\n",
    "         y_train = y_train,\n",
    "         idx_train = idx_train,\n",
    "         x_test = x_test,\n",
    "         idx_test = idx_test)\n",
    "\n",
    "print('Saved dataset 1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ecb233",
   "metadata": {},
   "source": [
    "# Dataset 2 creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d1e23c",
   "metadata": {},
   "source": [
    "# 2a: GSR, find rows with all 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd6d1e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all-0 GSR rows, TRAIN: 253 out of 2070(12.222222222222221%)\n",
      "Number of all-0 GSR rows, TEST: 64 out of 986(6.490872210953347%)\n"
     ]
    }
   ],
   "source": [
    "idx_not_train = []\n",
    "i = 0\n",
    "for hft in handcrafted_features_train['GSR_features']:\n",
    "    if np.nansum(hft) == 0:\n",
    "        idx_not_train.append(i)\n",
    "    i = i+1\n",
    "idx_not_train = np.unique(idx_not_train).tolist()\n",
    "print('Number of all-0 GSR rows, TRAIN: ' + str(len(idx_not_train)) +' out of ' + str(handcrafted_features_train['GSR_features'].shape[0]) + '(' + str(100*len(idx_not_train)/handcrafted_features_train['ECG_features'].shape[0]) + '%)')\n",
    "\n",
    "idx_not_test = []\n",
    "i = 0\n",
    "for hft in handcrafted_features_test['GSR_features']:\n",
    "    if np.nansum(hft) == 0:\n",
    "        idx_not_test.append(i)\n",
    "    i = i+1\n",
    "idx_not_test = np.unique(idx_not_test).tolist()\n",
    "print('Number of all-0 GSR rows, TEST: ' + str(len(idx_not_test)) +' out of ' + str(handcrafted_features_test['GSR_features'].shape[0]) + '(' + str(100*len(idx_not_test)/handcrafted_features_test['ECG_features'].shape[0]) + '%)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3847538c",
   "metadata": {},
   "source": [
    "# 2b: Drop and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd965348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of rows, TRAIN: 1817 out of 2070 (87.77777777777777%)\n",
      "Final number of rows, TEST: 922 out of 986 (93.50912778904666%)\n",
      "Prevalence of CLASS = 0, TRAIN: 54.870665932856355%\n",
      "Prevalence of CLASS = 1, TRAIN: 45.129334067143645%\n",
      "Saved dataset 2\n"
     ]
    }
   ],
   "source": [
    "#Drop train data\n",
    "x_train = dict()\n",
    "x_train['ECG_features'] = np.delete(handcrafted_features_train['ECG_features'],idx_not_train,axis=0)\n",
    "x_train['GSR_features'] = np.delete(handcrafted_features_train['GSR_features'],idx_not_train,axis=0)\n",
    "y_train = np.delete(y_train_orig,idx_not_train,axis=0)\n",
    "idx_train = [c for c in range(handcrafted_features_train['GSR_features'].shape[0]) if c not in idx_not_train]\n",
    "\n",
    "#Drop test data\n",
    "x_test = dict()\n",
    "x_test['ECG_features'] = np.delete(handcrafted_features_test['ECG_features'],idx_not_test,axis=0)\n",
    "x_test['GSR_features'] = np.delete(handcrafted_features_test['GSR_features'],idx_not_test,axis=0)\n",
    "idx_test = [c for c in range(handcrafted_features_test['GSR_features'].shape[0]) if c not in idx_not_test]\n",
    "\n",
    "#Print stats\n",
    "print('Final number of rows, TRAIN: ' + str(len(idx_train)) +' out of ' + str(handcrafted_features_train['ECG_features'].shape[0]) + ' (' + str(100*len(idx_train)/handcrafted_features_train['ECG_features'].shape[0]) + '%)')\n",
    "print('Final number of rows, TEST: ' + str(len(idx_test)) +' out of ' + str(handcrafted_features_test['ECG_features'].shape[0]) + ' (' + str(100*len(idx_test)/handcrafted_features_test['ECG_features'].shape[0]) + '%)')\n",
    "\n",
    "print('Prevalence of CLASS = 0, TRAIN: ' + str(100*np.sum(y_train)/y_train.shape[0]) + '%')\n",
    "print('Prevalence of CLASS = 1, TRAIN: ' + str(100*(y_train.shape[0]-np.sum(y_train))/y_train.shape[0]) + '%')\n",
    "\n",
    "#Save\n",
    "np.savez(os.path.join('data', 'preprocessed', 'preprocessed_dataset_2'), \n",
    "         x_train =x_train,\n",
    "         y_train = y_train,\n",
    "         idx_train = idx_train,\n",
    "         x_test = x_test,\n",
    "         idx_test = idx_test)\n",
    "\n",
    "print('Saved dataset 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eadeca2",
   "metadata": {},
   "source": [
    "# Dataset 3 creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a875f0f",
   "metadata": {},
   "source": [
    "# 3a: ECG, find rows with nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c63b3c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ECG rows with nans, TRAIN: 29 out of 2070(1.4009661835748792%)\n",
      "Number of ECG rows with nans, TEST: 73 out of 986(7.403651115618661%)\n"
     ]
    }
   ],
   "source": [
    "#Idxs of nans\n",
    "idx_not_train = np.unique(np.argwhere(np.isnan(handcrafted_features_train['ECG_features']))[:,0]).tolist()\n",
    "\n",
    "#Number of rows with nans\n",
    "print('Number of ECG rows with nans, TRAIN: ' + str(len(idx_not_train)) + ' out of ' + str(handcrafted_features_train['ECG_features'].shape[0]) + '(' + str(100*len(idx_not_train)/handcrafted_features_train['ECG_features'].shape[0]) + '%)')\n",
    "\n",
    "#Idxs of nans\n",
    "idx_not_test = np.unique(np.argwhere(np.isnan(handcrafted_features_test['ECG_features']))[:,0]).tolist()\n",
    "\n",
    "#Number of rows with nans\n",
    "print('Number of ECG rows with nans, TEST: ' + str(len(idx_not_test)) + ' out of ' + str(handcrafted_features_test['ECG_features'].shape[0]) + '(' + str(100*len(idx_not_test)/handcrafted_features_test['ECG_features'].shape[0]) + '%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3a8899",
   "metadata": {},
   "source": [
    "# 3b: ECG, find rows with all 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93277266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all-0 or nan ECG rows, TRAIN: 256 out of 2070(12.367149758454106%)\n",
      "Number of all-0 or nan ECG rows, TEST: 114 out of 986(11.561866125760648%)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for hft in handcrafted_features_train['ECG_features']:\n",
    "    if np.nansum(hft) == 0:\n",
    "        idx_not_train.append(i)\n",
    "    i = i+1\n",
    "idx_not_train = np.unique(idx_not_train).tolist()\n",
    "print('Number of all-0 or nan ECG rows, TRAIN: ' + str(len(idx_not_train)) +' out of ' + str(handcrafted_features_train['ECG_features'].shape[0]) + '(' + str(100*len(idx_not_train)/handcrafted_features_train['ECG_features'].shape[0]) + '%)')\n",
    "\n",
    "i = 0\n",
    "for hft in handcrafted_features_test['ECG_features']:\n",
    "    if np.nansum(hft) == 0:\n",
    "        idx_not_test.append(i)\n",
    "    i = i+1\n",
    "idx_not_test = np.unique(idx_not_test).tolist()\n",
    "print('Number of all-0 or nan ECG rows, TEST: ' + str(len(idx_not_test)) +' out of ' + str(handcrafted_features_test['ECG_features'].shape[0]) + '(' + str(100*len(idx_not_test)/handcrafted_features_test['ECG_features'].shape[0]) + '%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b98a6d",
   "metadata": {},
   "source": [
    "# 3c: GSR, find rows with all 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba3e52f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all-0 or nan ECG or all-0 GSR rows, TRAIN: 403 out of 2070(19.468599033816425%)\n",
      "Number of all-0 or nan ECG or all-0 GSR rows, TEST: 173 out of 986(17.545638945233264%)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for hft in handcrafted_features_train['GSR_features']:\n",
    "    if np.nansum(hft) == 0:\n",
    "        idx_not_train.append(i)\n",
    "    i = i+1\n",
    "idx_not_train = np.unique(idx_not_train).tolist()\n",
    "print('Number of all-0 or nan ECG or all-0 GSR rows, TRAIN: ' + str(len(idx_not_train)) +' out of ' + str(handcrafted_features_train['GSR_features'].shape[0]) + '(' + str(100*len(idx_not_train)/handcrafted_features_train['ECG_features'].shape[0]) + '%)')\n",
    "\n",
    "i = 0\n",
    "for hft in handcrafted_features_test['GSR_features']:\n",
    "    if np.nansum(hft) == 0:\n",
    "        idx_not_test.append(i)\n",
    "    i = i+1\n",
    "idx_not_test = np.unique(idx_not_test).tolist()\n",
    "print('Number of all-0 or nan ECG or all-0 GSR rows, TEST: ' + str(len(idx_not_test)) +' out of ' + str(handcrafted_features_test['GSR_features'].shape[0]) + '(' + str(100*len(idx_not_test)/handcrafted_features_test['ECG_features'].shape[0]) + '%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594ea034",
   "metadata": {},
   "source": [
    "# 3d: Drop and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "096bff7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of rows, TRAIN: 1667 out of 2070 (80.53140096618357%)\n",
      "Final number of rows, TEST: 813 out of 986 (82.45436105476674%)\n",
      "Prevalence of CLASS = 0, TRAIN: 55.48890221955609%\n",
      "Prevalence of CLASS = 1, TRAIN: 44.51109778044391%\n",
      "Saved dataset 3\n"
     ]
    }
   ],
   "source": [
    "#Drop train data\n",
    "x_train = dict()\n",
    "x_train['ECG_features'] = np.delete(handcrafted_features_train['ECG_features'],idx_not_train,axis=0)\n",
    "x_train['GSR_features'] = np.delete(handcrafted_features_train['GSR_features'],idx_not_train,axis=0)\n",
    "y_train = np.delete(y_train_orig,idx_not_train,axis=0)\n",
    "idx_train = [c for c in range(handcrafted_features_train['GSR_features'].shape[0]) if c not in idx_not_train]\n",
    "\n",
    "#Drop test data\n",
    "x_test = dict()\n",
    "x_test['ECG_features'] = np.delete(handcrafted_features_test['ECG_features'],idx_not_test,axis=0)\n",
    "x_test['GSR_features'] = np.delete(handcrafted_features_test['GSR_features'],idx_not_test,axis=0)\n",
    "idx_test = [c for c in range(handcrafted_features_test['GSR_features'].shape[0]) if c not in idx_not_test]\n",
    "\n",
    "#Print stats\n",
    "print('Final number of rows, TRAIN: ' + str(len(idx_train)) +' out of ' + str(handcrafted_features_train['ECG_features'].shape[0]) + ' (' + str(100*len(idx_train)/handcrafted_features_train['ECG_features'].shape[0]) + '%)')\n",
    "print('Final number of rows, TEST: ' + str(len(idx_test)) +' out of ' + str(handcrafted_features_test['ECG_features'].shape[0]) + ' (' + str(100*len(idx_test)/handcrafted_features_test['ECG_features'].shape[0]) + '%)')\n",
    "\n",
    "print('Prevalence of CLASS = 0, TRAIN: ' + str(100*np.sum(y_train)/y_train.shape[0]) + '%')\n",
    "print('Prevalence of CLASS = 1, TRAIN: ' + str(100*(y_train.shape[0]-np.sum(y_train))/y_train.shape[0]) + '%')\n",
    "\n",
    "#Save\n",
    "np.savez(os.path.join('data', 'preprocessed', 'preprocessed_dataset_3'), \n",
    "         x_train =x_train,\n",
    "         y_train = y_train,\n",
    "         idx_train = idx_train,\n",
    "         x_test = x_test,\n",
    "         idx_test = idx_test)\n",
    "\n",
    "print('Saved dataset 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a9844a",
   "metadata": {},
   "source": [
    "# Dataset 4 creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048d20aa",
   "metadata": {},
   "source": [
    "# 4a: ECG, find rows with nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1da1fb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ECG rows with nans, TRAIN: 29 out of 2070(1.4009661835748792%)\n",
      "Number of ECG rows with nans, TEST: 73 out of 986(7.403651115618661%)\n"
     ]
    }
   ],
   "source": [
    "#Idxs of nans\n",
    "idx_not_train = np.unique(np.argwhere(np.isnan(handcrafted_features_train['ECG_features']))[:,0]).tolist()\n",
    "\n",
    "#Number of rows with nans\n",
    "print('Number of ECG rows with nans, TRAIN: ' + str(len(idx_not_train)) + ' out of ' + str(handcrafted_features_train['ECG_features'].shape[0]) + '(' + str(100*len(idx_not_train)/handcrafted_features_train['ECG_features'].shape[0]) + '%)')\n",
    "\n",
    "#Idxs of nans\n",
    "idx_not_test = np.unique(np.argwhere(np.isnan(handcrafted_features_test['ECG_features']))[:,0]).tolist()\n",
    "\n",
    "#Number of rows with nans\n",
    "print('Number of ECG rows with nans, TEST: ' + str(len(idx_not_test)) + ' out of ' + str(handcrafted_features_test['ECG_features'].shape[0]) + '(' + str(100*len(idx_not_test)/handcrafted_features_test['ECG_features'].shape[0]) + '%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723e8582",
   "metadata": {},
   "source": [
    "# 4b: ECG, find rows with all 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae1a6b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all-0 or nan ECG rows, TRAIN: 256 out of 2070(12.367149758454106%)\n",
      "Number of all-0 or nan ECG rows, TEST: 114 out of 986(11.561866125760648%)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for hft in handcrafted_features_train['ECG_features']:\n",
    "    if np.nansum(hft) == 0:\n",
    "        idx_not_train.append(i)\n",
    "    i = i+1\n",
    "idx_not_train = np.unique(idx_not_train).tolist()\n",
    "print('Number of all-0 or nan ECG rows, TRAIN: ' + str(len(idx_not_train)) +' out of ' + str(handcrafted_features_train['ECG_features'].shape[0]) + '(' + str(100*len(idx_not_train)/handcrafted_features_train['ECG_features'].shape[0]) + '%)')\n",
    "\n",
    "i = 0\n",
    "for hft in handcrafted_features_test['ECG_features']:\n",
    "    if np.nansum(hft) == 0:\n",
    "        idx_not_test.append(i)\n",
    "    i = i+1\n",
    "idx_not_test = np.unique(idx_not_test).tolist()\n",
    "print('Number of all-0 or nan ECG rows, TEST: ' + str(len(idx_not_test)) +' out of ' + str(handcrafted_features_test['ECG_features'].shape[0]) + '(' + str(100*len(idx_not_test)/handcrafted_features_test['ECG_features'].shape[0]) + '%)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b042b920",
   "metadata": {},
   "source": [
    "# 4c: Drop and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2562878b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of rows, TRAIN: 1814 out of 2070 (87.6328502415459%)\n",
      "Final number of rows, TEST: 872 out of 986 (88.43813387423936%)\n",
      "Prevalence of CLASS = 0, TRAIN: 54.07938257993385%\n",
      "Prevalence of CLASS = 1, TRAIN: 45.92061742006615%\n",
      "Saved dataset 4\n"
     ]
    }
   ],
   "source": [
    "#Drop train data\n",
    "x_train = dict()\n",
    "x_train['ECG_features'] = np.delete(handcrafted_features_train['ECG_features'],idx_not_train,axis=0)\n",
    "y_train = np.delete(y_train_orig,idx_not_train,axis=0)\n",
    "idx_train = [c for c in range(handcrafted_features_train['GSR_features'].shape[0]) if c not in idx_not_train]\n",
    "\n",
    "#Drop test data\n",
    "x_test = dict()\n",
    "x_test['ECG_features'] = np.delete(handcrafted_features_test['ECG_features'],idx_not_test,axis=0)\n",
    "idx_test = [c for c in range(handcrafted_features_test['GSR_features'].shape[0]) if c not in idx_not_test]\n",
    "\n",
    "#Print stats\n",
    "print('Final number of rows, TRAIN: ' + str(len(idx_train)) +' out of ' + str(handcrafted_features_train['ECG_features'].shape[0]) + ' (' + str(100*len(idx_train)/handcrafted_features_train['ECG_features'].shape[0]) + '%)')\n",
    "print('Final number of rows, TEST: ' + str(len(idx_test)) +' out of ' + str(handcrafted_features_test['ECG_features'].shape[0]) + ' (' + str(100*len(idx_test)/handcrafted_features_test['ECG_features'].shape[0]) + '%)')\n",
    "\n",
    "print('Prevalence of CLASS = 0, TRAIN: ' + str(100*np.sum(y_train)/y_train.shape[0]) + '%')\n",
    "print('Prevalence of CLASS = 1, TRAIN: ' + str(100*(y_train.shape[0]-np.sum(y_train))/y_train.shape[0]) + '%')\n",
    "\n",
    "#Save\n",
    "np.savez(os.path.join('data', 'preprocessed', 'preprocessed_dataset_4'), \n",
    "         x_train =x_train,\n",
    "         y_train = y_train,\n",
    "         idx_train = idx_train,\n",
    "         x_test = x_test,\n",
    "         idx_test = idx_test)\n",
    "\n",
    "print('Saved dataset 4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ecd151",
   "metadata": {},
   "source": [
    "# Dataset 4 creation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438c485c",
   "metadata": {},
   "source": [
    "# 5a: GSR, find rows with all 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a446a6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all-0 GSR rows, TRAIN: 253 out of 2070(12.222222222222221%)\n",
      "Number of all-0 GSR rows, TEST: 64 out of 986(6.490872210953347%)\n"
     ]
    }
   ],
   "source": [
    "idx_not_train = []\n",
    "i = 0\n",
    "for hft in handcrafted_features_train['GSR_features']:\n",
    "    if np.nansum(hft) == 0:\n",
    "        idx_not_train.append(i)\n",
    "    i = i+1\n",
    "idx_not_train = np.unique(idx_not_train).tolist()\n",
    "print('Number of all-0 GSR rows, TRAIN: ' + str(len(idx_not_train)) +' out of ' + str(handcrafted_features_train['GSR_features'].shape[0]) + '(' + str(100*len(idx_not_train)/handcrafted_features_train['ECG_features'].shape[0]) + '%)')\n",
    "\n",
    "idx_not_test = []\n",
    "i = 0\n",
    "for hft in handcrafted_features_test['GSR_features']:\n",
    "    if np.nansum(hft) == 0:\n",
    "        idx_not_test.append(i)\n",
    "    i = i+1\n",
    "idx_not_test = np.unique(idx_not_test).tolist()\n",
    "print('Number of all-0 GSR rows, TEST: ' + str(len(idx_not_test)) +' out of ' + str(handcrafted_features_test['GSR_features'].shape[0]) + '(' + str(100*len(idx_not_test)/handcrafted_features_test['ECG_features'].shape[0]) + '%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65816c5",
   "metadata": {},
   "source": [
    "# 5b: Drop and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "678697bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of rows, TRAIN: 1817 out of 2070 (87.77777777777777%)\n",
      "Final number of rows, TEST: 922 out of 986 (93.50912778904666%)\n",
      "Prevalence of CLASS = 0, TRAIN: 54.870665932856355%\n",
      "Prevalence of CLASS = 1, TRAIN: 45.129334067143645%\n",
      "Saved dataset 5\n"
     ]
    }
   ],
   "source": [
    "#Drop train data\n",
    "x_train = dict()\n",
    "x_train['GSR_features'] = np.delete(handcrafted_features_train['GSR_features'],idx_not_train,axis=0)\n",
    "y_train = np.delete(y_train_orig,idx_not_train,axis=0)\n",
    "idx_train = [c for c in range(handcrafted_features_train['GSR_features'].shape[0]) if c not in idx_not_train]\n",
    "\n",
    "#Drop test data\n",
    "x_test = dict()\n",
    "x_test['GSR_features'] = np.delete(handcrafted_features_test['GSR_features'],idx_not_test,axis=0)\n",
    "idx_test = [c for c in range(handcrafted_features_test['GSR_features'].shape[0]) if c not in idx_not_test]\n",
    "\n",
    "#Print stats\n",
    "print('Final number of rows, TRAIN: ' + str(len(idx_train)) +' out of ' + str(handcrafted_features_train['ECG_features'].shape[0]) + ' (' + str(100*len(idx_train)/handcrafted_features_train['ECG_features'].shape[0]) + '%)')\n",
    "print('Final number of rows, TEST: ' + str(len(idx_test)) +' out of ' + str(handcrafted_features_test['ECG_features'].shape[0]) + ' (' + str(100*len(idx_test)/handcrafted_features_test['ECG_features'].shape[0]) + '%)')\n",
    "\n",
    "print('Prevalence of CLASS = 0, TRAIN: ' + str(100*np.sum(y_train)/y_train.shape[0]) + '%')\n",
    "print('Prevalence of CLASS = 1, TRAIN: ' + str(100*(y_train.shape[0]-np.sum(y_train))/y_train.shape[0]) + '%')\n",
    "\n",
    "#Save\n",
    "np.savez(os.path.join('data', 'preprocessed', 'preprocessed_dataset_5'), \n",
    "         x_train =x_train,\n",
    "         y_train = y_train,\n",
    "         idx_train = idx_train,\n",
    "         x_test = x_test,\n",
    "         idx_test = idx_test)\n",
    "\n",
    "print('Saved dataset 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842c872d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
